{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import csv\n",
    "import pandas as pd\n",
    "def load_data(data_path):\n",
    "\n",
    "    data_input = []\n",
    "    data_output = []\n",
    "    #df = pd.df\n",
    "    with open(data_path, 'r') as f:\n",
    "        rdr = csv.reader(f, delimiter=',', quotechar='\"')\n",
    "        for index, row in enumerate(rdr):\n",
    "            data_output.append(int(row[0]))\n",
    "            txt = \"\"\n",
    "            for s in row[1:]:\n",
    "                txt = txt + \" \" + s.replace(\"\\\\\", \" \")\n",
    "            txt = txt.lower() \n",
    "            data_input.append(txt[1:])\n",
    "\n",
    "    return data_input, data_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>News</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wall st. bears claw back into the black (reute...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>carlyle looks toward commercial aerospace (reu...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oil and economy cloud stocks' outlook (reuters...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iraq halts oil exports from main southern pipe...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oil prices soar to all-time record, posing new...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                News  Labels\n",
       "0  wall st. bears claw back into the black (reute...       3\n",
       "1  carlyle looks toward commercial aerospace (reu...       3\n",
       "2  oil and economy cloud stocks' outlook (reuters...       3\n",
       "3  iraq halts oil exports from main southern pipe...       3\n",
       "4  oil prices soar to all-time record, posing new...       3"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X, train_y = load_data(\"./data/ag_news_csv/train.csv\")\n",
    "train_df = pd.DataFrame(data={'News': train_X, 'Labels': train_y})\n",
    "\n",
    "test_X, test_y = load_data(\"./data/ag_news_csv/test.csv\")\n",
    "test_df = pd.DataFrame(data={'News': test_X, 'Labels': test_y})\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df.to_csv('./data/ag_news_csv/preprocessed_train.csv', index=False)\n",
    "test_df.to_csv('./data/ag_news_csv/preprocessed_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>News</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wall st. bears claw back into the black (reute...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>carlyle looks toward commercial aerospace (reu...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oil and economy cloud stocks' outlook (reuters...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iraq halts oil exports from main southern pipe...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oil prices soar to all-time record, posing new...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                News  Labels\n",
       "0  wall st. bears claw back into the black (reute...       3\n",
       "1  carlyle looks toward commercial aerospace (reu...       3\n",
       "2  oil and economy cloud stocks' outlook (reuters...       3\n",
       "3  iraq halts oil exports from main southern pipe...       3\n",
       "4  oil prices soar to all-time record, posing new...       3"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('./data/ag_news_csv/preprocessed_train.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "from torchtext.vocab import Vectors, GloVe\n",
    "\n",
    "def load_dataset(test_sen=None):\n",
    "\n",
    "    \"\"\"\n",
    "    tokenizer : Breaks sentences into a list of words. If sequential=False, no tokenization is applied\n",
    "    Field : A class that stores information about the way of preprocessing\n",
    "    fix_length : An important property of TorchText is that we can let the input to be variable length, and TorchText will\n",
    "                 dynamically pad each sequence to the longest sequence in that \"batch\". But here we are using fi_length which\n",
    "                 will pad each sequence to have a fix length of 200.\n",
    "                 \n",
    "    build_vocab : It will first make a vocabulary or dictionary mapping all the unique words present in the train_data to an\n",
    "                  idx and then after it will use GloVe word embedding to map the index to the corresponding word embedding.\n",
    "                  \n",
    "    vocab.vectors : This returns a torch tensor of shape (vocab_size x embedding_dim) containing the pre-trained word embeddings.\n",
    "    BucketIterator : Defines an iterator that batches examples of similar lengths together to minimize the amount of padding needed.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    tokenize = lambda x: x.split()\n",
    "    TEXT = data.Field(sequential=True, tokenize=tokenize, lower=True, include_lengths=True, batch_first=True, fix_length=200)\n",
    "    LABEL = data.LabelField(tensor_type=torch.FloatTensor)\n",
    "    datafields = [(\"News\", TEXT),\n",
    "                  (\"Label\", LABEL)]\n",
    "    train_data, test_data = TabularDataset.splits(\n",
    "                               path=\"./data/ag_news_csv\", # the root directory where the data lies\n",
    "                               train='preprocessed_train.csv', test=\"preprocessed_test.csv\",\n",
    "                               format='csv',\n",
    "                               skip_header=True, # if your csv header has a header, make sure to pass this to ensure it doesn't get proceesed as data!\n",
    "                               fields=datafields)\n",
    "    TEXT.build_vocab(train_data, vectors=GloVe(name='6B', dim=300))\n",
    "    LABEL.build_vocab(train_data)\n",
    "\n",
    "    word_embeddings = TEXT.vocab.vectors\n",
    "    print (\"Length of Text Vocabulary: \" + str(len(TEXT.vocab)))\n",
    "    print (\"Vector size of Text Vocabulary: \", TEXT.vocab.vectors.size())\n",
    "    print (\"Label Length: \" + str(len(LABEL.vocab)))\n",
    "\n",
    "    train_data, valid_data = train_data.split() # Further splitting of training_data to create new training_data & validation_data\n",
    "    train_iter, valid_iter, test_iter = data.BucketIterator.splits((train_data, valid_data, test_data), batch_size=32, sort_key=lambda x: len(x.text), repeat=False, shuffle=True)\n",
    "\n",
    "    '''Alternatively we can also use the default configurations'''\n",
    "    # train_iter, test_iter = datasets.IMDB.iters(batch_size=32)\n",
    "\n",
    "    vocab_size = len(TEXT.vocab)\n",
    "\n",
    "    return TEXT, vocab_size, word_embeddings, train_iter, valid_iter, test_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading aclImdb_v1.tar.gz\n"
     ]
    }
   ],
   "source": [
    "tokenize = lambda x: x.split()\n",
    "TEXT = data.Field(sequential=True, tokenize=tokenize, lower=True, include_lengths=True, batch_first=True, fix_length=200)\n",
    "LABEL = data.LabelField(tensor_type=torch.FloatTensor)\n",
    "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in train_data:\n",
    "    if i == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtext.data.example.Example at 0x1a217d72e8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.examples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
