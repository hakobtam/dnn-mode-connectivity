{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tabulate\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import load_data\n",
    "import models\n",
    "import curves\n",
    "import utils\n",
    "\n",
    "\n",
    "c_dir = './eval_polychain'                # training directory \n",
    "num_points = 61                 # number of points on the curve\n",
    "batch_size = 64                 # input batch size\n",
    "model_name = 'LSTMClassifier'   # model name\n",
    "curve_type = 'PolyChain'        # curve type to use\n",
    "num_bends = 3                   # number of curve bends\n",
    "ckpt = './saved_models/LSTMClassifier_curve_polychain4_5-22.pt'  \n",
    "#ckpt = './saved_models/LSTMClassifier_curve2-35.pt' # checkpoint of polychain\n",
    "wd = 1e-4                       # weight decay\n",
    "\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Text Vocabulary: 135872\n",
      "Vector size of Text Vocabulary:  torch.Size([135872, 300])\n",
      "Label Length: 4\n"
     ]
    }
   ],
   "source": [
    "TEXT, vocab_size, num_classes, word_embeddings, train_loader, valid_loader, test_loader = \\\n",
    "                                load_data.load_dataset(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "752c0dbf1d224a35b005a8b7f2271882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1594), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cb224a272ae40de9c3b64958fdc6c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=119), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------  ------------  -----------  -----------------  ----------  ----------------\n",
      "         t    Train loss    Train nll    Train error (%)    Test nll    Test error (%)\n",
      "----------  ------------  -----------  -----------------  ----------  ----------------\n",
      "    0.0000      127.1520       0.0140             0.6016      0.4701           10.5462\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f62a5acbf32d4ba0bc2d424996bee13b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1594), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fabb9d85d5f94404b9758ef37d761a45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=119), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    0.0167      127.1130       0.0109             0.4649      0.4789           10.4202\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c562984b43934470b0c7df62eec2932a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1594), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-1909a8523e53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mprevious_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mtr_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0mte_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mtr_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtr_res\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dnn-mode-connectivity/utils.py\u001b[0m in \u001b[0;36meval_model\u001b[0;34m(val_loader, model, loss_fn, batch_size, regularizer, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mregularizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mregularizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mnum_corrects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "kwargs = {\n",
    "    'batch_size': batch_size,\n",
    "    'hidden_size': 256,\n",
    "    'embedding_length': 300,\n",
    "    'vocab_size': vocab_size,\n",
    "    'weights': word_embeddings\n",
    "}\n",
    "\n",
    "architecture = getattr(models, model_name)\n",
    "curve = getattr(curves, curve_type)\n",
    "model = curves.CurveNet(\n",
    "    num_classes,\n",
    "    curve,\n",
    "    architecture.curve,\n",
    "    num_bends,\n",
    "    architecture_kwargs=kwargs,\n",
    ")\n",
    "model.cuda()\n",
    "checkpoint = torch.load(ckpt)\n",
    "model.load_state_dict(checkpoint['model_state'])\n",
    "\n",
    "#criterion = F.cross_entropy\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "regularizer = curves.l2_regularizer(wd)\n",
    "\n",
    "T = num_points\n",
    "ts = np.linspace(0.0, 1.0, T)\n",
    "tr_loss = np.zeros(T)\n",
    "tr_nll = np.zeros(T)\n",
    "tr_acc = np.zeros(T)\n",
    "te_loss = np.zeros(T)\n",
    "te_nll = np.zeros(T)\n",
    "te_acc = np.zeros(T)\n",
    "tr_err = np.zeros(T)\n",
    "te_err = np.zeros(T)\n",
    "dl = np.zeros(T)\n",
    "\n",
    "previous_weights = None\n",
    "\n",
    "columns = ['t', 'Train loss', 'Train nll', 'Train error (%)', 'Test nll', 'Test error (%)']\n",
    "\n",
    "t = torch.FloatTensor([0.0]).cuda()\n",
    "for i, t_value in enumerate(ts):\n",
    "    t.data.fill_(t_value)\n",
    "    weights = model.weights(t)\n",
    "    if previous_weights is not None:\n",
    "        dl[i] = np.sqrt(np.sum(np.square(weights - previous_weights)))\n",
    "    previous_weights = weights.copy()\n",
    "\n",
    "    tr_res = utils.eval_model(train_loader, model, criterion, batch_size, regularizer, t=t)\n",
    "    te_res = utils.eval_model(test_loader, model, criterion, batch_size, regularizer, t=t)\n",
    "    tr_loss[i] = tr_res['loss']\n",
    "    tr_nll[i] = tr_res['nll']\n",
    "    tr_acc[i] = tr_res['acc']\n",
    "    tr_err[i] = 100.0 - tr_acc[i]\n",
    "    te_loss[i] = te_res['loss']\n",
    "    te_nll[i] = te_res['nll']\n",
    "    te_acc[i] = te_res['acc']\n",
    "    te_err[i] = 100.0 - te_acc[i]\n",
    "\n",
    "    values = [t, tr_loss[i], tr_nll[i], tr_err[i], te_nll[i], te_err[i]]\n",
    "    table = tabulate.tabulate([values], columns, tablefmt='simple', floatfmt='10.4f')\n",
    "    if i % 40 == 0:\n",
    "        table = table.split('\\n')\n",
    "        table = '\\n'.join([table[1]] + table)\n",
    "    else:\n",
    "        table = table.split('\\n')[2]\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 227.92\n",
      "                      start         end         min         max         avg         int\n",
      "---------------  ----------  ----------  ----------  ----------  ----------  ----------\n",
      "train loss         126.5277    126.4215    126.0718    126.5277    126.1584    126.1808\n",
      "train nll            0.1489      0.1054      0.0973      0.1679      0.1400      0.1352\n",
      "train error (%)      5.9125      3.8877      3.6647      6.8814      5.5700      5.3511\n",
      "test nll             0.2413      0.2365      0.2321      0.2677      0.2514      0.2490\n",
      "test error (%)       9.3109      8.8866      8.6050      9.9832      9.3545      9.2545\n"
     ]
    }
   ],
   "source": [
    "def stats(values, dl):\n",
    "    min = np.min(values)\n",
    "    max = np.max(values)\n",
    "    avg = np.mean(values)\n",
    "    int = np.sum(0.5 * (values[:-1] + values[1:]) * dl[1:]) / np.sum(dl[1:])\n",
    "    return min, max, avg, int\n",
    "\n",
    "\n",
    "tr_loss_min, tr_loss_max, tr_loss_avg, tr_loss_int = stats(tr_loss, dl)\n",
    "tr_nll_min, tr_nll_max, tr_nll_avg, tr_nll_int = stats(tr_nll, dl)\n",
    "tr_err_min, tr_err_max, tr_err_avg, tr_err_int = stats(tr_err, dl)\n",
    "\n",
    "te_loss_min, te_loss_max, te_loss_avg, te_loss_int = stats(te_loss, dl)\n",
    "te_nll_min, te_nll_max, te_nll_avg, te_nll_int = stats(te_nll, dl)\n",
    "te_err_min, te_err_max, te_err_avg, te_err_int = stats(te_err, dl)\n",
    "\n",
    "print('Length: %.2f' % np.sum(dl))\n",
    "print(tabulate.tabulate([\n",
    "        ['train loss', tr_loss[0], tr_loss[-1], tr_loss_min, tr_loss_max, tr_loss_avg, tr_loss_int],\n",
    "        ['train nll', tr_nll[0], tr_nll[-1], tr_nll_min, tr_nll_max, tr_nll_avg, tr_nll_int],\n",
    "        ['train error (%)', tr_err[0], tr_err[-1], tr_err_min, tr_err_max, tr_err_avg, tr_err_int],\n",
    "        ['test nll', te_nll[0], te_nll[-1], te_nll_min, te_nll_max, te_nll_avg, te_nll_int],\n",
    "        ['test error (%)', te_err[0], te_err[-1], te_err_min, te_err_max, te_err_avg, te_err_int],\n",
    "    ], [\n",
    "        '', 'start', 'end', 'min', 'max', 'avg', 'int'\n",
    "    ], tablefmt='simple', floatfmt='10.4f'))\n",
    "\n",
    "np.savez(\n",
    "    os.path.join(c_dir, 'curve4_5.npz'),\n",
    "    ts=ts,\n",
    "    dl=dl,\n",
    "    tr_loss=tr_loss,\n",
    "    tr_loss_min=tr_loss_min,\n",
    "    tr_loss_max=tr_loss_max,\n",
    "    tr_loss_avg=tr_loss_avg,\n",
    "    tr_loss_int=tr_loss_int,\n",
    "    tr_nll=tr_nll,\n",
    "    tr_nll_min=tr_nll_min,\n",
    "    tr_nll_max=tr_nll_max,\n",
    "    tr_nll_avg=tr_nll_avg,\n",
    "    tr_nll_int=tr_nll_int,\n",
    "    tr_acc=tr_acc,\n",
    "    tr_err=tr_err,\n",
    "    tr_err_min=tr_err_min,\n",
    "    tr_err_max=tr_err_max,\n",
    "    tr_err_avg=tr_err_avg,\n",
    "    tr_err_int=tr_err_int,\n",
    "    te_loss=te_loss,\n",
    "    te_loss_min=te_loss_min,\n",
    "    te_loss_max=te_loss_max,\n",
    "    te_loss_avg=te_loss_avg,\n",
    "    te_loss_int=te_loss_int,\n",
    "    te_nll=te_nll,\n",
    "    te_nll_min=te_nll_min,\n",
    "    te_nll_max=te_nll_max,\n",
    "    te_nll_avg=te_nll_avg,\n",
    "    te_nll_int=te_nll_int,\n",
    "    te_acc=te_acc,\n",
    "    te_err=te_err,\n",
    "    te_err_min=te_err_min,\n",
    "    te_err_max=te_err_max,\n",
    "    te_err_avg=te_err_avg,\n",
    "    te_err_int=te_err_int,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 276.64\n",
      "                      start         end         min         max         avg         int\n",
      "---------------  ----------  ----------  ----------  ----------  ----------  ----------\n",
      "train loss         126.6103    126.5062    126.1005    126.6103    126.2208    126.2160\n",
      "train nll            0.1365      0.1529      0.1332      0.1785      0.1552      0.1555\n",
      "train error (%)      4.9589      5.7280      4.9043      6.7911      5.9461      5.9605\n",
      "test nll             0.2443      0.2474      0.2327      0.2589      0.2423      0.2423\n",
      "test error (%)       9.4118      9.4706      8.6218      9.7731      9.1926      9.1982\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 260.22\n",
      "                      start         end         min         max         avg         int\n",
      "---------------  ----------  ----------  ----------  ----------  ----------  ----------\n",
      "train loss         126.6103    126.5062    126.1128    126.6103    126.2265    126.2219\n",
      "train error (%)      4.9589      5.7280      4.8802      8.0267      6.3322      6.3456\n",
      "test nll             0.2443      0.2474      0.2294      0.2629      0.2422      0.2422\n",
      "test error (%)       9.4118      9.4706      8.7521      9.7773      9.2828      9.2867\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
